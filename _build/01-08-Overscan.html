---
redirect_from:
  - "01-08-overscan"
interact_link: content/01-08-Overscan.ipynb
kernel_name: python3
has_widgets: false
title: |-
  Overscan
prev_page:
  url: /01-06-Image-combination.html
  title: |-
    Image combination
next_page:
  url: /01-09-Calibration-choices-you-need-to-make.html
  title: |-
    Calibration choices to make
suffix: .ipynb

comment: "***PROGRAMMATICALLY GENERATED, DO NOT EDIT. SEE ORIGINAL FILES IN /content***"
---

    <main class="jupyter-page">
    
<div class="jb_cell">

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h1 id="Overscan">Overscan<a class="anchor-link" href="#Overscan"> </a></h1>
</div>
</div>
</div>
</div>

<div class="jb_cell">

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>The overscan region of a CCD, if present, is a part of the chip that is covered.
Depending on the camera, it can be a useful way to remove small variations in
the bias level from frame to frame.</p>
<p>However, whether or not the overscan is useful depends on the camera. It's
advisable to examine the overscan part of the camera you're using before
deciding if you should include it in image reduction.</p>
<p>One important note: <em>overscan always includes bias, read noise, and dark
current</em>. The overscan pixels are still pixels, and just like any other pixel
includes dark current and is subject to read noise. Many sources describe
overscan as correcting for bias, but if the dark current for the camera is
negligible, as it often is for cryogenically cooled cameras, then the overscan
is essentially bias.</p>
<p>The read noise in the overscan is reduced by averaging over the overscan region.
That will be covered in a later notebook; this notebook focuses on what the
overscan looks like and how to decide whether or not to use it.</p>
<p>In this notebook we will look at the overscan region for two different cameras,
a cryogenically cooled camera in which the overscan provides useful information
and a thermo-electrically cooled camera in which the overscan does not provide
useful information.</p>

</div>
</div>
</div>
</div>

<div class="jb_cell">

<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="kn">from</span> <span class="nn">pathlib</span> <span class="k">import</span> <span class="n">Path</span>

<span class="kn">from</span> <span class="nn">astropy.nddata</span> <span class="k">import</span> <span class="n">CCDData</span>
<span class="kn">from</span> <span class="nn">astropy.visualization</span> <span class="k">import</span> <span class="n">hist</span>
<span class="kn">from</span> <span class="nn">ccdproc</span> <span class="k">import</span> <span class="n">subtract_overscan</span>
<span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="nn">plt</span>

<span class="kn">from</span> <span class="nn">convenience_functions</span> <span class="k">import</span> <span class="n">show_image</span>
</pre></div>

    </div>
</div>
</div>

</div>
</div>

<div class="jb_cell">

<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="c1"># Use custom style for larger fonts and figures</span>
<span class="n">plt</span><span class="o">.</span><span class="n">style</span><span class="o">.</span><span class="n">use</span><span class="p">(</span><span class="s1">&#39;guide.mplstyle&#39;</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

</div>
</div>

<div class="jb_cell">

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="Case-1:-Cryogenically-cooled-Large-Format-Camera-(LFC)-at-Palomar">Case 1: Cryogenically cooled Large Format Camera (LFC) at Palomar<a class="anchor-link" href="#Case-1:-Cryogenically-cooled-Large-Format-Camera-(LFC)-at-Palomar"> </a></h2><p><a href="https://github.com/mwcraig/ccd-reduction-and-photometry-guide/pull/213/files#diff-a39dc0de1b4b0c208cdeeb55123683a9R69"><em>Click here to comment on this section on GitHub (opens in new tab).</em></a>{:target="_blank"}</p>
<p>The images below are from chip 0 of the LFC at the Palomar 200-inch telescope.
Technical information about the camera is <a href="http://www.astro.caltech.edu/palomar/observer/200inchResources/lfcspecs.html">here</a>. It
turns out that the images are not actually 2048 × 4096; as you can see below,
the images are 2080 × 4128. The "extra" in each direction is overscan.</p>
<p>The FITS header for these files includes the keyword <code>BIASSEC</code>, which indicates
the nominal extent of the overscan region. Its value is <code>[2049:2080,1:4127]</code>,
which indicates the overscan extends from 2048 to 2079 (Python indexing starts
at 0, not 1 like in FITS) in the "short" direction and over the entire chip in
the other direction. As we'll see shortly, the useful overscan region is smaller
than this.</p>
<p>We'll focus here on the overscan in the side that is nominally 2048 wide; in
Python that's the second index. The pixel count cross-sections plotted below are
from a bias, science, and flat image. Flat images are particularly helpful in
evaluating how much of the overscan region is useful because the average pixel
value in the exposed part of the camera is typically large.</p>

</div>
</div>
</div>
</div>

<div class="jb_cell">

<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">cryo_path</span> <span class="o">=</span> <span class="n">Path</span><span class="p">(</span><span class="s1">&#39;example-cryo-LFC&#39;</span><span class="p">)</span>
<span class="n">bias_lfc</span> <span class="o">=</span> <span class="n">CCDData</span><span class="o">.</span><span class="n">read</span><span class="p">(</span><span class="n">cryo_path</span> <span class="o">/</span> <span class="s1">&#39;ccd.001.0.fits&#39;</span><span class="p">,</span> <span class="n">unit</span><span class="o">=</span><span class="s1">&#39;count&#39;</span><span class="p">)</span>
<span class="n">science_g_lfc</span> <span class="o">=</span> <span class="n">CCDData</span><span class="o">.</span><span class="n">read</span><span class="p">(</span><span class="n">cryo_path</span> <span class="o">/</span> <span class="s1">&#39;ccd.037.0.fits&#39;</span><span class="p">,</span> <span class="n">unit</span><span class="o">=</span><span class="s1">&#39;count&#39;</span><span class="p">)</span>
<span class="n">flat_g_lfc</span> <span class="o">=</span> <span class="n">CCDData</span><span class="o">.</span><span class="n">read</span><span class="p">(</span><span class="n">cryo_path</span> <span class="o">/</span> <span class="s1">&#39;ccd.014.0.fits&#39;</span><span class="p">,</span> <span class="n">unit</span><span class="o">=</span><span class="s1">&#39;count&#39;</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

</div>
</div>

<div class="jb_cell">

<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">bias_lfc</span><span class="o">.</span><span class="n">shape</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="jb_output_wrapper }}">
<div class="output_area">



<div class="output_text output_subarea output_execute_result">
<pre>(4128, 2080)</pre>
</div>

</div>
</div>
</div>
</div>

</div>
</div>

<div class="jb_cell">

<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">20</span><span class="p">,</span><span class="mi">10</span><span class="p">))</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">science_g_lfc</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">),</span> <span class="n">label</span><span class="o">=</span><span class="s1">&#39;Science image&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">bias_lfc</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">),</span> <span class="n">label</span><span class="o">=</span><span class="s1">&#39;Bias image&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">flat_g_lfc</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">),</span> <span class="n">label</span><span class="o">=</span><span class="s1">&#39;Flat image&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">grid</span><span class="p">()</span>
<span class="n">plt</span><span class="o">.</span><span class="n">axvline</span><span class="p">(</span><span class="n">x</span><span class="o">=</span><span class="mi">2048</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="s1">&#39;black&#39;</span><span class="p">,</span> <span class="n">linewidth</span><span class="o">=</span><span class="mi">3</span><span class="p">,</span> <span class="n">linestyle</span><span class="o">=</span><span class="s1">&#39;dashed&#39;</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s1">&#39;start of overscan&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">legend</span><span class="p">()</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ylim</span><span class="p">(</span><span class="mi">1000</span><span class="p">,</span> <span class="mi">2000</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlim</span><span class="p">(</span><span class="mi">2040</span><span class="p">,</span> <span class="mi">2090</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s1">&#39;pixel number&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s1">&#39;Counts&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s1">&#39;Overscan region, averaged over all rows&#39;</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="jb_output_wrapper }}">
<div class="output_area">



<div class="output_text output_subarea output_execute_result">
<pre>Text(0.5, 1.0, &#39;Overscan region, averaged over all rows&#39;)</pre>
</div>

</div>
</div>
<div class="jb_output_wrapper }}">
<div class="output_area">



<div class="output_png output_subarea ">
<img src="images/01-08-Overscan_7_1.png"
>
</div>

</div>
</div>
</div>
</div>

</div>
</div>

<div class="jb_cell">

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h3 id="Discussion-of-Example-1">Discussion of Example 1<a class="anchor-link" href="#Discussion-of-Example-1"> </a></h3><p><a href="https://github.com/mwcraig/ccd-reduction-and-photometry-guide/pull/213/files#diff-a39dc0de1b4b0c208cdeeb55123683a9R135"><em>Click here to comment on this section on GitHub (opens in new tab).</em></a>{:target="_blank"}</p>
<p>There are a few interesting things here.</p>
<p><strong>The count value is nearly uniform in the overscan region.</strong></p>
<p>This is good; ideally the overscan is nearly uniform since the pixels are not
illuminated.</p>
<p><strong>Some light leaks from the imaging region into the overscan region.</strong></p>
<p>This is
clearest in the flat image, where the counts are much higher than the value to
which they asymptote until at least pixel number 2055.</p>
<p>Though the FITS header indicates the overscan starts at pixel 2048, the <em>useful</em>
part of the overscan (i.e. the part not contaminated by light) extends from
pixel 2055 to the end.</p>
<p><strong>There is an offset between the science image and the other two images, and
perhaps between the flat and bias images.</strong></p>
<p>This sort of variation is what overscan is intended to correct. It could be that
this one science image has a different overscan value (it was taken several
hours after the flat image) or it could be that all science images have a
different overscan value than other types of images.</p>
<p>Either way, subtracting overscan from each of the images allows for correction
of these offsets.</p>
<p><strong>Dark current <em>in this camera</em> is essentially zero so the overscan is
measuring bias.</strong></p>
<p>To be clear, this isn't apparent from the graph above, but cryogenically cooled
cameras have negligible dark current.</p>
<h4 id="What-happens-if-you-don't-use-the-overscan?">What happens if you don't use the overscan?<a class="anchor-link" href="#What-happens-if-you-don't-use-the-overscan?"> </a></h4><p><a href="https://github.com/mwcraig/ccd-reduction-and-photometry-guide/pull/213/files#diff-a39dc0de1b4b0c208cdeeb55123683a9R171"><em>Click here to comment on this section on GitHub (opens in new tab).</em></a>{:target="_blank"}</p>
<p>Nothing particularly bad. In the specific case above, ignoring the overscan will
shift the background level in the science image by roughly 20 counts, since the
difference between the overscan region of the science image is lower than the
overscan in the other images by roughly 20 counts. If, before doing science, the
background of those images is subtracted, then this shift should be removed with
the background.</p>

</div>
</div>
</div>
</div>

<div class="jb_cell">

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h3 id="Conclusion-for-case-1">Conclusion for case 1<a class="anchor-link" href="#Conclusion-for-case-1"> </a></h3><p><a href="https://github.com/mwcraig/ccd-reduction-and-photometry-guide/pull/213/files#diff-a39dc0de1b4b0c208cdeeb55123683a9R185"><em>Click here to comment on this section on GitHub (opens in new tab).</em></a>{:target="_blank"}</p>
<p>The overscan is useful, but the usable overscan region extends from 2055 to the
end of the chip rather than from 2048 to end of the chip as the FITS header
claims. Put a little differently, the appropriate <code>BIASSEC</code> for these images is
<code>[2056:2080,1:4127]</code>. (Note that FITS starts numbering at 1 instead of 0, so
2055 in Python is 2056 in FITS notation.)</p>
<p>If the science you are using requires knowing the counts to a precision of a
count or two, and modeling the background in the science image isn't an option,
consider using the overscan.</p>

</div>
</div>
</div>
</div>

<div class="jb_cell">

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="Case-2:-Thermo-electrically-cooled-Apogee-Aspen-CG16M">Case 2: Thermo-electrically cooled Apogee Aspen CG16M<a class="anchor-link" href="#Case-2:-Thermo-electrically-cooled-Apogee-Aspen-CG16M"> </a></h2><p><a href="https://github.com/mwcraig/ccd-reduction-and-photometry-guide/pull/213/files#diff-a39dc0de1b4b0c208cdeeb55123683a9R202"><em>Click here to comment on this section on GitHub (opens in new tab).</em></a>{:target="_blank"}</p>
<p>This is a low-end, research-grade CCD sold by Andor. Basic information is
<a href="https://andor.oxinst.com/assets/uploads/documents/Andor/apogee/Apogee_Aspen_CG16M_Specifications.pdf">here</a>, though you need to track down the description
of the sensor chip, <a href="http://www.onsemi.com/pub/Collateral/KAF-16803-D.PDF">KAF-16803 CCD</a> to find out that the
overscan region of this 4096 × 4096 pixel camera extends from pixel 4097 to 4109
along one of the directions.</p>

</div>
</div>
</div>
</div>

<div class="jb_cell">

<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">therma_path</span> <span class="o">=</span> <span class="n">Path</span><span class="p">(</span><span class="s1">&#39;example-thermo-electric&#39;</span><span class="p">)</span>
<span class="n">kelt</span> <span class="o">=</span> <span class="n">CCDData</span><span class="o">.</span><span class="n">read</span><span class="p">(</span><span class="n">therma_path</span> <span class="o">/</span> <span class="s1">&#39;kelt-16-b-S001-R001-C084-r.fit&#39;</span><span class="p">,</span> <span class="n">unit</span><span class="o">=</span><span class="s1">&#39;adu&#39;</span><span class="p">)</span>
<span class="n">dark1000</span> <span class="o">=</span> <span class="n">CCDData</span><span class="o">.</span><span class="n">read</span><span class="p">(</span><span class="s1">&#39;dark-test-0002d1000.fit.bz2&#39;</span><span class="p">,</span> <span class="n">unit</span><span class="o">=</span><span class="s1">&#39;adu&#39;</span><span class="p">)</span>
<span class="n">flat</span> <span class="o">=</span> <span class="n">CCDData</span><span class="o">.</span><span class="n">read</span><span class="p">(</span><span class="n">therma_path</span> <span class="o">/</span> <span class="s1">&#39;AutoFlat-PANoRot-r-Bin1-006.fit&#39;</span><span class="p">,</span> <span class="n">unit</span><span class="o">=</span><span class="s1">&#39;adu&#39;</span><span class="p">)</span>
<span class="n">master</span> <span class="o">=</span> <span class="n">CCDData</span><span class="o">.</span><span class="n">read</span><span class="p">(</span><span class="s1">&#39;combined_bias_100_images.fit.bz2&#39;</span><span class="p">,</span> <span class="n">unit</span><span class="o">=</span><span class="s1">&#39;adu&#39;</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="jb_output_wrapper }}">
<div class="output_area">

<div class="output_subarea output_stream output_stdout output_text">
<pre>INFO: using the unit adu passed to the FITS reader instead of the unit adu in the FITS file. [astropy.nddata.ccddata]
</pre>
</div>
</div>
</div>
<div class="jb_output_wrapper }}">
<div class="output_area">

<div class="output_subarea output_stream output_stderr output_text">
<pre>WARNING: FITSFixedWarning: RADECSYS= &#39;FK5 &#39; / Equatorial coordinate system 
the RADECSYS keyword is deprecated, use RADESYSa. [astropy.wcs.wcs]
</pre>
</div>
</div>
</div>
<div class="jb_output_wrapper }}">
<div class="output_area">

<div class="output_subarea output_stream output_stdout output_text">
<pre>INFO: using the unit adu passed to the FITS reader instead of the unit adu in the FITS file. [astropy.nddata.ccddata]
INFO: using the unit adu passed to the FITS reader instead of the unit adu in the FITS file. [astropy.nddata.ccddata]
</pre>
</div>
</div>
</div>
</div>
</div>

</div>
</div>

<div class="jb_cell">

<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">20</span><span class="p">,</span><span class="mi">10</span><span class="p">))</span>

<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">kelt</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">),</span> <span class="n">label</span><span class="o">=</span><span class="s1">&#39;night sky average&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">master</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">),</span> <span class="n">label</span><span class="o">=</span><span class="s1">&#39;100 bias combined&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">dark1000</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">),</span> <span class="n">label</span><span class="o">=</span><span class="s1">&#39;1000sec dark average&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">flat</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">),</span> <span class="n">label</span><span class="o">=</span><span class="s1">&#39;flat average&#39;</span><span class="p">)</span>

<span class="n">plt</span><span class="o">.</span><span class="n">grid</span><span class="p">()</span>
<span class="n">plt</span><span class="o">.</span><span class="n">axvline</span><span class="p">(</span><span class="n">x</span><span class="o">=</span><span class="mi">4096</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="s1">&#39;black&#39;</span><span class="p">,</span> <span class="n">linewidth</span><span class="o">=</span><span class="mi">3</span><span class="p">,</span> <span class="n">linestyle</span><span class="o">=</span><span class="s1">&#39;dashed&#39;</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s1">&#39;start of overscan&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">legend</span><span class="p">()</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlim</span><span class="p">(</span><span class="mi">4090</span><span class="p">,</span> <span class="mi">4110</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ylim</span><span class="p">(</span><span class="mi">900</span><span class="p">,</span> <span class="mi">1300</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="jb_output_wrapper }}">
<div class="output_area">



<div class="output_text output_subarea output_execute_result">
<pre>(900, 1300)</pre>
</div>

</div>
</div>
<div class="jb_output_wrapper }}">
<div class="output_area">



<div class="output_png output_subarea ">
<img src="images/01-08-Overscan_12_1.png"
>
</div>

</div>
</div>
</div>
</div>

</div>
</div>

<div class="jb_cell">

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h3 id="Discussion-of-Example-2">Discussion of Example 2<a class="anchor-link" href="#Discussion-of-Example-2"> </a></h3><p><a href="https://github.com/mwcraig/ccd-reduction-and-photometry-guide/pull/213/files#diff-a39dc0de1b4b0c208cdeeb55123683a9R248"><em>Click here to comment on this section on GitHub (opens in new tab).</em></a>{:target="_blank"}</p>
<p>The camera also has some interesting features.</p>
<p><strong>Count values change quite a bit in the overscan region</strong></p>
<p>This is clearest in the overscan for the flat. Not only is light leaking into
the overscan, the overscan appears to be mostly light leakage. One pixel may be
useful at best.</p>
<p><strong>Overscan includes dark current</strong></p>
<p>The overscan for the dark image in the figure above is roughly 10 counts higher
than the counts for the bias. The dark current for this camera is roughly 0.01
counts/pixel/second. For a 1000 second dark exposure, the expected dark counts
are about 10, which is the difference seen in the graph.</p>
<p><strong>There is an offset between the bias/dark and science/flat images</strong></p>
<p>The offset in this camera is roughly 50 counts. It's large enough that one ought
to be hesitant to use the overscan for this camera.</p>
<p><strong>The overscan counts are higher than the average bias counts</strong></p>
<p>Note that for the bias image, counts increase up to the pixel where overscan
starts and then level out. It turns out that overscan counts are <em>higher</em> than
the average of the bias counts, so subtracting the overscan would lead to a bias
image that is negative. This is another reason to be suspicious of the overscan
region on this camera.</p>

</div>
</div>
</div>
</div>

<div class="jb_cell">

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h3 id="Conclusion-for-case-2">Conclusion for case 2<a class="anchor-link" href="#Conclusion-for-case-2"> </a></h3><p><a href="https://github.com/mwcraig/ccd-reduction-and-photometry-guide/pull/213/files#diff-a39dc0de1b4b0c208cdeeb55123683a9R283"><em>Click here to comment on this section on GitHub (opens in new tab).</em></a>{:target="_blank"}</p>
<p>Do not use the overscan in this case. There are serious issues with light
leakage and large differences in the overscan counts between the bias and
science images.</p>

</div>
</div>
</div>
</div>

 


    </main>
    